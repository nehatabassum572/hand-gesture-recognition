{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8b0e8a33",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "928cc415",
   "metadata": {},
   "source": [
    "## INTIALIZING VARIABLES "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e2524f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing some global variables that will be used throughout the program.\n",
    "background = None\n",
    "hand = None\n",
    "frames_elapsed = 0\n",
    "FRAME_HEIGHT = 500\n",
    "FRAME_WIDTH = 600\n",
    "CALIBRATION_TIME = 30\n",
    "BG_WEIGHT = 0.5\n",
    "OBJ_THRESHOLD = 18"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cd2be6a",
   "metadata": {},
   "source": [
    "## HAND DATA CLASS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "36532cf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hold the hand's data so all its details are in one place.\n",
    "# This class will store the coordinates of the hand's bounding box and other related data.\n",
    "class HandData:\n",
    "    top = (0,0)\n",
    "    bottom = (0,0)\n",
    "    left = (0,0)\n",
    "    right = (0,0)\n",
    "    centerX = 0\n",
    "    prevCenterX = 0\n",
    "    isInFrame = False\n",
    "    isWaving = False\n",
    "    fingers = None\n",
    "    gestureList = []\n",
    "    \n",
    "    def __init__(self, top, bottom, left, right, centerX):\n",
    "        self.top = top\n",
    "        self.bottom = bottom\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "        self.centerX = centerX\n",
    "        self.prevCenterX = 0\n",
    "        isInFrame = False\n",
    "        isWaving = False\n",
    "        \n",
    "    def update(self, top, bottom, left, right):\n",
    "        self.top = top\n",
    "        self.bottom = bottom\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "    def check_for_waving(self, centerX):\n",
    "        self.prevCenterX = self.centerX\n",
    "        self.centerX = centerX\n",
    "        \n",
    "        if abs(self.centerX - self.prevCenterX > 3):\n",
    "            self.isWaving = True\n",
    "        else:\n",
    "            self.isWaving = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8aceb760",
   "metadata": {},
   "source": [
    "## PRINT FUNCTION "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "687c0114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we take the current frame, the number of frames elapsed, and how many fingers we've detected\n",
    "# so we can print on the screen which gesture is happening (or if the camera is calibrating).\n",
    "def print_on_image(frame, hand):\n",
    "    text = \"Searching...\"\n",
    "\n",
    "    if frames_elapsed < CALIBRATION_TIME:\n",
    "        text = \"Calibrating...\"\n",
    "    elif hand == None or hand.isInFrame == False:\n",
    "        text = \"No hand detected\"\n",
    "    else:\n",
    "        if hand.isWaving:\n",
    "            text = \"Waving\"\n",
    "        elif hand.fingers == 0:\n",
    "            text = \"Rock\"\n",
    "        elif hand.fingers == 1:\n",
    "            text = \"Pointing\"\n",
    "        elif hand.fingers == 2:\n",
    "            text = \"Scissors\"\n",
    "    \n",
    "    cv2.putText(frame, text, (10,20), cv2.FONT_HERSHEY_COMPLEX, 0.4,( 0 , 0 , 0 ),2,cv2.LINE_AA)\n",
    "    cv2.putText(frame, text, (10,20), cv2.FONT_HERSHEY_COMPLEX, 0.4,(255,255,255),1,cv2.LINE_AA)\n",
    "\n",
    "    # Highlight the region of interest using a drawn rectangle.\n",
    "    cv2.rectangle(frame, (region_left, region_top), (region_right, region_bottom), (255,255,255), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca577fdd",
   "metadata": {},
   "source": [
    "## RECOGNIZE WHEN HAND IN ROI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "55949284",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_region(frame):\n",
    "    # Separate the region of interest from the rest of the frame.\n",
    "    region = frame[region_top:region_bottom, region_left:region_right]\n",
    "    # Make it grayscale so we can detect the edges more easily.\n",
    "    region = cv2.cvtColor(region, cv2.COLOR_BGR2GRAY)\n",
    "    # Use a Gaussian blur to prevent frame noise from being labeled as an edge.\n",
    "    region = cv2.GaussianBlur(region, (5,5), 0)\n",
    "\n",
    "    return region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3840c000",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_average(region):\n",
    "    global background\n",
    "    # If we haven't captured the background yet, make the current region the background.\n",
    "    if background is None:\n",
    "        background = region.copy().astype(\"float\")\n",
    "        return\n",
    "    # Otherwise, add this captured frame to the average of the backgrounds.\n",
    "    cv2.accumulateWeighted(region, background, BG_WEIGHT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "88b420e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here we use differencing to separate the background from the object of interest.\n",
    "def segment(region):\n",
    "    global hand\n",
    "    # absolute difference between the background and the current frame.\n",
    "    diff = cv2.absdiff(background.astype(np.uint8), region)\n",
    "\n",
    "    # Threshold that region with a strict 0 or 1 ruling so only the foreground remains.\n",
    "    thresholded_region = cv2.threshold(diff, OBJ_THRESHOLD, 255, cv2.THRESH_BINARY)[1]\n",
    "\n",
    "    # Get the contours of the region, which will return an outline of the hand.\n",
    "    contours, hierarchy = cv2.findContours(thresholded_region.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "    # If we didn't get anything, there's no hand.\n",
    "    if len(contours) == 0:\n",
    "        if hand is not None:\n",
    "            hand.isInFrame = False\n",
    "        return\n",
    "    # Otherwise return a tuple of the filled hand (thresholded_region), along with the outline (segmented_region).\n",
    "    else:\n",
    "        if hand is not None:\n",
    "            hand.isInFrame = True\n",
    "        segmented_region = max(contours, key = cv2.contourArea)\n",
    "        return (thresholded_region, segmented_region)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "101f84b8",
   "metadata": {},
   "source": [
    "## GET HAND DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74553378",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_hand_data(thresholded_image, segmented_image):\n",
    "    global hand\n",
    "    \n",
    "    # Enclose the area around the extremities in a convex hull to connect all outcroppings.\n",
    "    convexHull = cv2.convexHull(segmented_image)\n",
    "    \n",
    "    # Find the extremities for the convex hull and store them as points.\n",
    "    top    = tuple(convexHull[convexHull[:, :, 1].argmin()][0])\n",
    "    bottom = tuple(convexHull[convexHull[:, :, 1].argmax()][0])\n",
    "    left   = tuple(convexHull[convexHull[:, :, 0].argmin()][0])\n",
    "    right  = tuple(convexHull[convexHull[:, :, 0].argmax()][0])\n",
    "    \n",
    "    # Get the center of the palm, so we can check for waving and find the fingers.\n",
    "    centerX = int((left[0] + right[0]) / 2)\n",
    "    \n",
    "    # We put all the info into an object for handy extraction (get it? HANDy?)\n",
    "    if hand == None:\n",
    "        hand = HandData(top, bottom, left, right, centerX)\n",
    "    else:\n",
    "        hand.update(top, bottom, left, right)\n",
    "    \n",
    "    # Only check for waving every 6 frames.\n",
    "    if frames_elapsed % 6 == 0:\n",
    "        hand.check_for_waving(centerX)\n",
    "    \n",
    "    # We count the number of fingers up every frame, but only change hand.fingers if\n",
    "    # 12 frames have passed, to prevent erratic gesture counts.\n",
    "    hand.gestureList.append(count_fingers(thresholded_image))\n",
    "    if frames_elapsed % 12 == 0:\n",
    "        hand.fingers = most_frequent(hand.gestureList)\n",
    "        hand.gestureList.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a533a65",
   "metadata": {},
   "source": [
    "## COUNT FINGERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db563e00",
   "metadata": {},
   "outputs": [],
   "source": [
    "def count_fingers(thresholded_image):\n",
    "    # Validate input\n",
    "    if thresholded_image is None or thresholded_image.size == 0:\n",
    "        print(\"Error: thresholded_image is invalid\")\n",
    "        return 0\n",
    "    \n",
    "    # Ensure thresholded_image is grayscale and uint8\n",
    "    if len(thresholded_image.shape) == 3:\n",
    "        thresholded_image = cv2.cvtColor(thresholded_image, cv2.COLOR_BGR2GRAY)\n",
    "    thresholded_image = thresholded_image.astype(np.uint8)\n",
    "\n",
    "    # Find the height at which to draw the line to count fingers\n",
    "    line_height = int(hand.top[1] + (0.2 * (hand.bottom[1] - hand.top[1])))\n",
    "\n",
    "    # Create a blank image for the line with dtype=np.uint8\n",
    "    line = np.zeros(thresholded_image.shape[:2], dtype=np.uint8)\n",
    "\n",
    "    # Draw a line across the region of interest\n",
    "    cv2.line(line, (thresholded_image.shape[1], line_height), (0, line_height), 255, 1)\n",
    "\n",
    "    # Perform bitwise AND to find intersections\n",
    "    line = cv2.bitwise_and(thresholded_image, thresholded_image, mask=line)\n",
    "\n",
    "    # Get contours (OpenCV 4.x+ compatible)\n",
    "    contours, _ = cv2.findContours(line.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)\n",
    "\n",
    "    fingers = 0\n",
    "\n",
    "    # Count fingers by checking contour widths\n",
    "    for curr in contours:\n",
    "        width = len(curr)  # Number of points in the contour\n",
    "        if width < 3 * abs(hand.right[0] - hand.left[0]) / 4 and width > 5:\n",
    "            fingers += 1\n",
    "\n",
    "    return fingers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "55c2a3f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def most_frequent(input_list):\n",
    "    dict = {}\n",
    "    count = 0\n",
    "    most_freq = 0\n",
    "    \n",
    "    for item in reversed(input_list):\n",
    "        dict[item] = dict.get(item, 0) + 1\n",
    "        if dict[item] >= count :\n",
    "            count, most_freq = dict[item], item\n",
    "    \n",
    "    return most_freq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e28c380",
   "metadata": {},
   "source": [
    "## MAIN FUNCTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37c149ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our region of interest will be the top right part of the frame. This is where we will look for the hand.\n",
    "region_top = 0\n",
    "region_bottom = int(2 * FRAME_HEIGHT / 3)\n",
    "region_left = int(FRAME_WIDTH / 2)\n",
    "region_right = FRAME_WIDTH\n",
    "\n",
    "frames_elapsed = 0\n",
    "\n",
    "capture = cv2.VideoCapture(0)\n",
    "\n",
    "while (True):\n",
    "    # Store the frame from the video capture and resize it to the window size.\n",
    "    ret, frame = capture.read()\n",
    "    frame = cv2.resize(frame, (FRAME_WIDTH, FRAME_HEIGHT))\n",
    "    frame = cv2.flip(frame, 1)# Flip the frame horizontally for a mirror effect.\n",
    "\n",
    "    # Separate the region of interest and prep it for edge detection.\n",
    "    region = get_region(frame)\n",
    "    if frames_elapsed < CALIBRATION_TIME:\n",
    "        get_average(region)\n",
    "    else:\n",
    "        region_pair = segment(region)\n",
    "        if region_pair is not None:\n",
    "            # If we have the regions segmented successfully, show them in another window for the user.\n",
    "            (thresholded_region, segmented_region) = region_pair\n",
    "            cv2.drawContours(region, [segmented_region], -1, (255, 255, 255))\n",
    "            cv2.imshow(\"Segmented Image\", region)\n",
    "\n",
    "            get_hand_data(thresholded_region, segmented_region)\n",
    "    \n",
    "    # Write the action the hand is doing on the screen, and draw the region of interest.\n",
    "    print_on_image(frame, hand)\n",
    "    cv2.imshow(\"Camera Input\", frame)\n",
    "    frames_elapsed += 1\n",
    "    # Check if user wants to exit. If the user presses 'x', we break the loop and exit the program.\n",
    "    # The waitKey function waits for 1 millisecond for a key press.\n",
    "    if (cv2.waitKey(1) & 0xFF == ord('x')):\n",
    "        break\n",
    "\n",
    "# When we exit the loop, we have to stop the capture too.\n",
    "capture.release()\n",
    "cv2.destroyAllWindows()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".recog",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
